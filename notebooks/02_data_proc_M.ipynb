{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "from cplAE_MET.utils.load_config import load_config\n",
    "from cplAE_MET.models.augmentations import undo_radial_correction\n",
    "from cplAE_MET.models.augmentations import do_radial_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the config file name\n",
    "config_file = 'config_preproc.toml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the input and output path\n",
    "def set_paths(config_file=None):\n",
    "    paths, _ = load_config(config_file=config_file, verbose=False)\n",
    "    paths['input'] = f'{str(paths[\"data_dir\"])}'\n",
    "    paths['arbor_density_file'] = f'{paths[\"input\"]}/{str(paths[\"arbor_density_file\"])}'\n",
    "\n",
    "    paths['specimen_ids'] = f'{paths[\"input\"]}/{str(paths[\"specimen_ids_file\"])}'\n",
    "    paths['m_data_folder'] = f'{paths[\"input\"]}/{str(paths[\"m_data_folder\"])}'\n",
    "    paths['m_anno'] = f'{paths[\"m_data_folder\"]}/{str(paths[\"m_anno\"])}'\n",
    "    paths['hist2d_120x4'] = f'{paths[\"m_data_folder\"]}/{str(paths[\"hist2d_120x4_folder\"])}'\n",
    "\n",
    "    paths['t_anno'] = f'{paths[\"input\"]}/{\"anno.feather\"}'\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define the arbor density channel names based on the class\n",
    "def get_file_apendix(exc_or_inh):\n",
    "    appendix = []\n",
    "    if exc_or_inh == \"inh\":\n",
    "        appendix = [\"axon\", \"dendrite\"]\n",
    "    if exc_or_inh == \"exc\":\n",
    "        appendix = [\"apical\", \"basal\"]\n",
    "    return appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove some cells that have only few non-zero pixels in their arbor density images\n",
    "def get_cell_ids_of_abnormal_images(specimen_ids, image_path, m_anno,  min_nonzero_pixels=5):\n",
    "    '''\n",
    "    Get all the specimen_ids that have few nonzero pixels\n",
    "\n",
    "    Args:\n",
    "        anno: annotation file, which has column called specimen_id\n",
    "        image_path: the path to the images\n",
    "        exc_or_inh: inh or exc cells are being processed\n",
    "        min_nonzero_pixels: the cell is abnormal if it has less than this number of nonzero pixels\n",
    "\n",
    "    Returns:\n",
    "        list of specimen ids of the abnormal cell images\n",
    "    '''\n",
    "\n",
    "    ab_spec_id = []\n",
    "    for i, spec_id in tqdm(enumerate(specimen_ids)):\n",
    "        if spec_id in m_anno['specimen_id'].astype(str).to_list():\n",
    "            exc_or_inh = m_anno[m_anno['specimen_id'] == spec_id]['class']\n",
    "            app = get_file_apendix(exc_or_inh.values[0])\n",
    "            if os.path.isfile(image_path + f'/hist2d_120x4_{app[0]}_{spec_id}.csv'):\n",
    "\n",
    "                im0 = pd.read_csv(image_path + f'/hist2d_120x4_{app[0]}_{spec_id}.csv', header=None).values\n",
    "                im1 = pd.read_csv(image_path + f'/hist2d_120x4_{app[1]}_{spec_id}.csv', header=None).values\n",
    "\n",
    "                if np.count_nonzero(im0) < min_nonzero_pixels or np.count_nonzero(im1) < min_nonzero_pixels:\n",
    "                    ab_spec_id.append(spec_id)\n",
    "    return ab_spec_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the m_anno which is the metadata file for the m cells\n",
    "dir_pth = set_paths(config_file=config_file)\n",
    "m_anno_path = dir_pth['m_anno']\n",
    "hist2d_120x4_path = dir_pth[\"hist2d_120x4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16703it [05:09, 53.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 cells will be dropped because of the few non zero pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading m_anno and finding cells with few nonzero pixels\n",
    "ids = pd.read_csv(dir_pth['specimen_ids'])\n",
    "specimen_ids = ids['specimen_id'].astype(str).tolist()\n",
    "m_anno = pd.read_csv(m_anno_path) #This is used for soma depth and class type\n",
    "ab_spec_id = get_cell_ids_of_abnormal_images(specimen_ids, hist2d_120x4_path, m_anno,  min_nonzero_pixels=5)\n",
    "print(len(ab_spec_id), \"cells will be dropped because of the few non zero pixels\")\n",
    "drop_spec_id = ab_spec_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................\n",
      "Generating image for all the locked dataset, for those that we dont have M, we put zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16703it [04:31, 61.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so far in total 10246 cells have m data available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"...................................................\")\n",
    "print(\"Generating image for all the locked dataset, for those that we dont have M, we put zeros\")\n",
    "hist_shape = (1, 120, 4, 1)\n",
    "im_shape = (1, 120, 4, 4)\n",
    "im = np.zeros((len(specimen_ids), 120, 4, 4), dtype=float)\n",
    "soma_depth = np.zeros((len(specimen_ids),))\n",
    "c = 0\n",
    "for i, spec_id in tqdm(enumerate(specimen_ids)):\n",
    "    if spec_id in drop_spec_id:\n",
    "        im[i, ...] = np.full(im_shape, np.nan)\n",
    "        soma_depth[i] = np.nan\n",
    "    else:\n",
    "        if spec_id in m_anno['specimen_id'].astype(str).to_list():\n",
    "            exc_or_inh = m_anno[m_anno['specimen_id'] == spec_id]['class'].values[0]\n",
    "            app = get_file_apendix(exc_or_inh)\n",
    "            if os.path.isfile(hist2d_120x4_path + f'/hist2d_120x4_{app[0]}_{spec_id}.csv'):\n",
    "                c += 1\n",
    "                im0 = pd.read_csv(hist2d_120x4_path + f'/hist2d_120x4_{app[0]}_{spec_id}.csv', header=None).values\n",
    "                im1 = pd.read_csv(hist2d_120x4_path + f'/hist2d_120x4_{app[1]}_{spec_id}.csv', header=None).values\n",
    "\n",
    "                #convert arbor density to arbor mass\n",
    "                mass0 = undo_radial_correction(im0)\n",
    "                mass1 = undo_radial_correction(im1)\n",
    "\n",
    "                # Normalize so that the mass sum is 350\n",
    "                mass0 = mass0 * 350 / np.sum(mass0)\n",
    "                mass1 = mass1 * 350 / np.sum(mass1)\n",
    "\n",
    "                # compute the arbor density from the arbor mass again\n",
    "                im0 = do_radial_correction(mass0)\n",
    "                im1 = do_radial_correction(mass1)\n",
    "\n",
    "                # convert images from 120x4 to 120x1 shape \n",
    "                # mass0 = mass0.sum(axis=1)\n",
    "                # mass1 = mass1.sum(axis=1)\n",
    "\n",
    "                # mass0 = mass0 * 100 / np.sum(mass0)\n",
    "                # mass1 = mass1 * 100 / np.sum(mass1)\n",
    "\n",
    "                im0 = mass0\n",
    "                im1 = mass1\n",
    "                \n",
    "                if exc_or_inh == \"inh\":\n",
    "                    im[i, :, :, 0:2] = (np.concatenate([im0.reshape(hist_shape), im1.reshape(hist_shape)], axis=3))\n",
    "                    im[i, :, :, 2:] = 0.\n",
    "                else:\n",
    "                    im[i, :, :, 2:] = (np.concatenate([im0.reshape(hist_shape), im1.reshape(hist_shape)], axis=3))\n",
    "                    im[i, :, :, 0:2] = 0.\n",
    "\n",
    "                soma_depth[i] = np.squeeze(m_anno.loc[m_anno['specimen_id'] == spec_id]['soma_depth'].values)\n",
    "            else:\n",
    "                im[i, ...] = np.full(im_shape, np.nan)\n",
    "                soma_depth[i] = np.nan\n",
    "        else:\n",
    "            im[i, ...] = np.full(im_shape, np.nan)\n",
    "            soma_depth[i] = np.nan\n",
    "\n",
    "print(\"so far in total\", c, \"cells have m data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat(dir_pth['arbor_density_file'], {'hist_ax_de_api_bas': im,\n",
    "                                'soma_depth': soma_depth,\n",
    "                                'specimen_id': ids['specimen_id'].astype(str).to_list()}, do_compression=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplae_met",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
