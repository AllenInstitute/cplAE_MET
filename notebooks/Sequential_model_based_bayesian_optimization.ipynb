{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model Based Optimization using the Tree Parzen Estimator for neural network model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four parts to an optimization problem:\n",
    "\n",
    "1. Objective function: what we want to minimize\n",
    "2. Domain space: values of the parameters over which to minimize the objective\n",
    "3. Hyperparameter optimization function: constructs the surrogate function and chooses next values to evaluate\n",
    "4. Trials: score, parameter pairs recorded each time we evaluate the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# From python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# From torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# From optuna\n",
    "import optuna\n",
    "\n",
    "# From CplAE_MET\n",
    "from cplAE_MET.models.train_tempcsfeatures_dev import set_paths, init_losses\n",
    "from cplAE_MET.utils.dataset import MET_exc_inh_v2\n",
    "from cplAE_MET.models.model_classes import Model_ME_T_v2\n",
    "from cplAE_MET.models.torch_utils import MET_dataset_v2\n",
    "from cplAE_MET.models.torch_utils import tonumpy\n",
    "from cplAE_MET.models.classification_functions import run_QDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=1000\n",
    "n_epochs=10\n",
    "\n",
    "# Read data and train test split -----------\n",
    "dir_pth = set_paths(\"config.toml\", exp_name=\"test\", fold_n=0)\n",
    "dat = MET_exc_inh_v2.from_file(dir_pth['MET_data'])\n",
    "train_ind, val_ind = dat.train_val_split(fold=0, n_folds=10, seed=0)\n",
    "train_dat = dat[train_ind,:]\n",
    "val_dat = dat[val_ind,:]\n",
    "T_labels = dat.cluster_label\n",
    "\n",
    "# Dataset and Dataloader -----------\n",
    "train_dataset = MET_dataset_v2(train_dat, device=device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_dataset = MET_dataset_v2(val_dat, device=device)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "dataset = MET_dataset_v2(dat, device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Criterion(x, loss_dict):\n",
    "    \"\"\"Objective function to minimize\"\"\"\n",
    "\n",
    "    criterion =  loss_dict['rec_t'] + loss_dict['rec_e'] + x * ( 0.5 * loss_dict['cpl_t->e'] + 0.5 * loss_dict['cpl_e->t']) + \\\n",
    "                 0 * (loss_dict['rec_m'] + (loss_dict['rec_m_me'] + loss_dict['rec_e_me']) + loss_dict['cpl_t->m'] + loss_dict['cpl_m->t'] + \\\n",
    "                 loss_dict['cpl_e->m'] + loss_dict['cpl_m->e'] +  loss_dict['cpl_t->me'] + loss_dict['cpl_me->t'] +  loss_dict['cpl_me->m'] + \\\n",
    "                 loss_dict['cpl_m->me'] + loss_dict['cpl_me->e'] + loss_dict['cpl_e->me']) \n",
    "    return criterion\n",
    "\n",
    "def build_model(params):\n",
    "    model_config = dict(latent_dim=3, \n",
    "                     batch_size=batch_size,\n",
    "                     augment_decoders=0,\n",
    "                     T=dict(dropout_p=0.2, \n",
    "                            alpha_T=1),\n",
    "                     E=dict(gnoise_std=train_dataset.gnoise_e_std,\n",
    "                            gnoise_std_frac=0.05, \n",
    "                            dropout_p=0.2, \n",
    "                            alpha_E=1),\n",
    "                     M=dict(gnoise_std=train_dataset.gnoise_m_std,\n",
    "                            gnoise_std_frac=0.005, \n",
    "                            dropout_p=0.2, \n",
    "                            alpha_M=0),\n",
    "                     TE=dict(lambda_TE=params['lambda_TE'], lambda_tune_T_E=0.5, lambda_tune_E_T=0.5),\n",
    "                     TM=dict(lambda_TM=0, lambda_tune_T_M=0, lambda_tune_M_T=0),\n",
    "                     ME=dict(alpha_ME=0, lambda_ME=0, lambda_tune_M_E=0, lambda_tune_E_M=0),\n",
    "                     ME_T=dict(lambda_ME_T=0, lambda_tune_ME_T=0, lambda_tune_T_ME=0),\n",
    "                     ME_M=dict(lambda_ME_M=0, lambda_tune_ME_M=0, lambda_tune_M_ME=0), \n",
    "                     ME_E=dict(lambda_ME_E=0, lambda_tune_ME_E=0, lambda_tune_E_ME=0),\n",
    "                     )  \n",
    "\n",
    "\n",
    "    model = Model_ME_T_v2(model_config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(param, model):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "\n",
    "    # Training -----------\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(iter(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass T, E -----------\n",
    "            loss_dict, _, _ = model(batch)\n",
    "            loss = Criterion(param['lambda_TE'], loss_dict)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step == 0:\n",
    "                train_loss = init_losses(loss_dict)\n",
    "        \n",
    "            # track loss over batches -----------\n",
    "            for k, v in loss_dict.items():\n",
    "                train_loss[k] += v\n",
    "\n",
    "        # Validation -----------\n",
    "        with torch.no_grad():\n",
    "            for val_batch in iter(val_dataloader):\n",
    "                model.eval()\n",
    "                val_loss, _, _ = model(val_batch)\n",
    "                \n",
    "            # Compute classification acc from the model latent dim for all data\n",
    "            for all_data in iter(dataloader):\n",
    "                _, z_dict, _ = model(all_data) \n",
    "            \n",
    "            isT_1d = dat.isT_1d\n",
    "            isTE_1d = np.logical_and(dat.isT_1d, dat.isE_1d)\n",
    "            zt_classification_acc, n_class, clf = run_QDA(tonumpy(z_dict['zt'])[isT_1d], \n",
    "                                                          T_labels[isT_1d],\n",
    "                                                          train_test_ids={'train':[i for i in train_ind if isT_1d[i]], \n",
    "                                                                          'val':[i for i in val_ind if isT_1d[i]]})\n",
    "\n",
    "            print(\"acc on the zt:\", zt_classification_acc, \"number of classes:\", n_class)\n",
    "            \n",
    "            ze_classification_acc , n_class, clf = run_QDA(z_dict['ze'][isTE_1d], \n",
    "                                                           T_labels[isTE_1d],\n",
    "                                                           test_size= 0.1)\n",
    "            \n",
    "            print(\"acc on the ze:\", ze_classification_acc, \"number of classes:\", n_class)\n",
    "\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Average losses over batches -----------\n",
    "        for k, v in train_loss.items():\n",
    "            train_loss[k] = train_loss[k] / len(train_dataloader)\n",
    "\n",
    "    return ze_classification_acc\n",
    "\n",
    "    \n",
    "def objective(trial):\n",
    "    params = {'lambda_TE': trial.suggest_float('lambda_TE', 0, 10)}\n",
    "    model = build_model(params)\n",
    "    accuracy = train_and_evaluate(params, model)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-04 11:53:12,646]\u001b[0m A new study created in memory with name: no-name-db9148f6-5371-433f-91d1-b84d51727e83\u001b[0m\n",
      "\u001b[33m[W 2023-01-04 11:53:16,768]\u001b[0m Trial 0 failed because of the following error: TypeError(\"can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3808220/485917395.py\", line 63, in objective\n",
      "    accuracy = train_and_evaluate(params, model)\n",
      "  File \"/tmp/ipykernel_3808220/485917395.py\", line 44, in train_and_evaluate\n",
      "    ze_classification_acc , n_class, clf = run_QDA(z_dict['ze'][isTE_1d],\n",
      "  File \"/home/fahimehb/Local/new_codes/cplAE_MET/cplAE_MET/models/classification_functions.py\", line 85, in run_QDA\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 851, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/torch/_tensor.py\", line 757, in __array__\n",
      "    return self.numpy()\n",
      "TypeError: can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc on the zt: 24.427480916030532 number of classes: 52\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler())\n\u001b[0;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [8], line 63\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     61\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlambda_TE\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mlambda_TE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m)}\n\u001b[1;32m     62\u001b[0m model \u001b[39m=\u001b[39m build_model(params)\n\u001b[0;32m---> 63\u001b[0m accuracy \u001b[39m=\u001b[39m train_and_evaluate(params, model)\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy\n",
      "Cell \u001b[0;32mIn [8], line 44\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(param, model)\u001b[0m\n\u001b[1;32m     37\u001b[0m     zt_classification_acc, n_class, clf \u001b[39m=\u001b[39m run_QDA(tonumpy(z_dict[\u001b[39m'\u001b[39m\u001b[39mzt\u001b[39m\u001b[39m'\u001b[39m])[isT_1d], \n\u001b[1;32m     38\u001b[0m                                                   T_labels[isT_1d],\n\u001b[1;32m     39\u001b[0m                                                   train_test_ids\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m train_ind \u001b[39mif\u001b[39;00m isT_1d[i]], \n\u001b[1;32m     40\u001b[0m                                                                   \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m:[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m val_ind \u001b[39mif\u001b[39;00m isT_1d[i]]})\n\u001b[1;32m     42\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39macc on the zt:\u001b[39m\u001b[39m\"\u001b[39m, zt_classification_acc, \u001b[39m\"\u001b[39m\u001b[39mnumber of classes:\u001b[39m\u001b[39m\"\u001b[39m, n_class)\n\u001b[0;32m---> 44\u001b[0m     ze_classification_acc , n_class, clf \u001b[39m=\u001b[39m run_QDA(z_dict[\u001b[39m'\u001b[39;49m\u001b[39mze\u001b[39;49m\u001b[39m'\u001b[39;49m][isTE_1d], \n\u001b[1;32m     45\u001b[0m                                                    T_labels[isTE_1d],\n\u001b[1;32m     46\u001b[0m                                                    test_size\u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39macc on the ze:\u001b[39m\u001b[39m\"\u001b[39m, ze_classification_acc, \u001b[39m\"\u001b[39m\u001b[39mnumber of classes:\u001b[39m\u001b[39m\"\u001b[39m, n_class)\n\u001b[1;32m     51\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Local/new_codes/cplAE_MET/cplAE_MET/models/classification_functions.py:85\u001b[0m, in \u001b[0;36mrun_QDA\u001b[0;34m(X, y, min_label_size, train_test_ids, test_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, stratify\u001b[39m=\u001b[39my, test_size\u001b[39m=\u001b[39mtest_size, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     84\u001b[0m clf \u001b[39m=\u001b[39m QuadraticDiscriminantAnalysis()\n\u001b[0;32m---> 85\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     86\u001b[0m classification_acc \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mscore(X_test, y_test) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m     87\u001b[0m n_class \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(Counter(y_test))\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:851\u001b[0m, in \u001b[0;36mQuadraticDiscriminantAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    828\u001b[0m     \u001b[39m\"\"\"Fit the model according to the given training data and parameters.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \n\u001b[1;32m    830\u001b[0m \u001b[39m        .. versionchanged:: 0.19\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 851\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y)\n\u001b[1;32m    852\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    853\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_, y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cplae_met/lib/python3.8/site-packages/torch/_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "isT_1d = dat.isT_1d\n",
    "classification_acc, n_class, clf = run_QDA(dat.XT[isT_1d, 0:83], \n",
    "                                           T_labels[isT_1d],\n",
    "                                           train_test_ids={'train':[i for i in train_ind if isT_1d[i]], \n",
    "                                                           'val':[i for i in val_ind if isT_1d[i]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.458015267175576 52\n"
     ]
    }
   ],
   "source": [
    "print(classification_acc, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/sklearn/metrics/_classification.py:217: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isTE_1d = np.logical_and(dat.isT_1d, dat.isE_1d)\n",
    "clf.score(np.nan_to_num(dat.XE[isTE_1d]), T_labels[isTE_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan_to_num(dat.XE[isTE_1d])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplae_met",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5eb60d146f8faf7ea6865a598c7f2e034e4748de202b0cf2037de6d3aa28423"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
