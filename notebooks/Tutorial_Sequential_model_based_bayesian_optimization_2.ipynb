{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model Based Optimization using the Tree Parzen Estimator for neural network model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four parts to an optimization problem:\n",
    "\n",
    "1. Objective function: what we want to minimize\n",
    "2. Domain space: values of the parameters over which to minimize the objective\n",
    "3. Hyperparameter optimization function: constructs the surrogate function and chooses next values to evaluate\n",
    "4. Trials: score, parameter pairs recorded each time we evaluate the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good old pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimehb/miniconda3/envs/cplae_met/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/fahimehb/Local/test/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a simple data generator to use in the model\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.labels = [0 if label == 0 else 1 for label in df['HeartDisease']]\n",
    "        self.features = df.drop(columns=['HeartDisease'], axis=1).values.tolist()\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        return np.array(self.features[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_features = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_features, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = Dataset(train_data), Dataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network model\n",
    "def build_model(params):\n",
    "    \n",
    "    in_features = 20\n",
    "    \n",
    "    return nn.Sequential(\n",
    "    \n",
    "        nn.Linear(in_features, params['n_unit']),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(params['n_unit'], 2),\n",
    "        nn.LeakyReLU()\n",
    "        \n",
    "    )\n",
    " \n",
    " \n",
    "# Train and evaluate the accuarcy of neural network model\n",
    "def train_and_evaluate(param, model):\n",
    "    \n",
    "    df = pd.read_csv('/home/fahimehb/Local/test/heart.csv')\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    train_data, val_data = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(optim, \"Adam\")(model.parameters(), lr= 0.001)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(30):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in train_dataloader:\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                train_input = train_input.to(device)\n",
    "\n",
    "                output = model(train_input.float())\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    val_input = val_input.to(device)\n",
    "\n",
    "                    output = model(val_input.float())\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            accuracy = total_acc_val/len(val_data)\n",
    "            print(accuracy)\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    " # Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy \n",
    "def objective(trial):\n",
    "\n",
    "     params = {\n",
    "            #   'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "            #   'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              'n_unit': trial.suggest_int(\"n_unit\", 4, 18)\n",
    "              }\n",
    "    \n",
    "     model = build_model(params)\n",
    "    \n",
    "     accuracy = train_and_evaluate(params, model)\n",
    "\n",
    "     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-03 15:13:16,626]\u001b[0m A new study created in memory with name: no-name-bbc0cbbf-6998-4160-bc5b-824eae1225c1\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:13:49,667]\u001b[0m Trial 0 finished with value: 0.5760869565217391 and parameters: {'n_unit': 5}. Best is trial 0 with value: 0.5760869565217391.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:14:18,140]\u001b[0m Trial 1 finished with value: 0.8532608695652174 and parameters: {'n_unit': 14}. Best is trial 1 with value: 0.8532608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:14:50,889]\u001b[0m Trial 2 finished with value: 0.8641304347826086 and parameters: {'n_unit': 5}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:15:24,385]\u001b[0m Trial 3 finished with value: 0.7717391304347826 and parameters: {'n_unit': 12}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:15:58,230]\u001b[0m Trial 4 finished with value: 0.7717391304347826 and parameters: {'n_unit': 11}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:16:15,933]\u001b[0m Trial 5 finished with value: 0.8532608695652174 and parameters: {'n_unit': 6}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:16:31,025]\u001b[0m Trial 6 finished with value: 0.8532608695652174 and parameters: {'n_unit': 14}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:16:46,150]\u001b[0m Trial 7 finished with value: 0.8097826086956522 and parameters: {'n_unit': 6}. Best is trial 2 with value: 0.8641304347826086.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:17:04,062]\u001b[0m Trial 8 finished with value: 0.875 and parameters: {'n_unit': 12}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:17:21,135]\u001b[0m Trial 9 finished with value: 0.8369565217391305 and parameters: {'n_unit': 17}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:17:43,802]\u001b[0m Trial 10 finished with value: 0.782608695652174 and parameters: {'n_unit': 9}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:18:08,529]\u001b[0m Trial 11 finished with value: 0.8152173913043478 and parameters: {'n_unit': 9}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:18:38,194]\u001b[0m Trial 12 finished with value: 0.8043478260869565 and parameters: {'n_unit': 9}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:19:09,816]\u001b[0m Trial 13 finished with value: 0.8478260869565217 and parameters: {'n_unit': 4}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:19:42,917]\u001b[0m Trial 14 finished with value: 0.8641304347826086 and parameters: {'n_unit': 17}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:20:09,363]\u001b[0m Trial 15 finished with value: 0.8206521739130435 and parameters: {'n_unit': 12}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:20:28,498]\u001b[0m Trial 16 finished with value: 0.8315217391304348 and parameters: {'n_unit': 7}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:20:52,740]\u001b[0m Trial 17 finished with value: 0.875 and parameters: {'n_unit': 15}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:21:25,605]\u001b[0m Trial 18 finished with value: 0.8532608695652174 and parameters: {'n_unit': 14}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:21:58,342]\u001b[0m Trial 19 finished with value: 0.7934782608695652 and parameters: {'n_unit': 16}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:22:20,460]\u001b[0m Trial 20 finished with value: 0.8641304347826086 and parameters: {'n_unit': 15}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:22:49,711]\u001b[0m Trial 21 finished with value: 0.8478260869565217 and parameters: {'n_unit': 18}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:23:22,055]\u001b[0m Trial 22 finished with value: 0.7771739130434783 and parameters: {'n_unit': 11}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:23:55,502]\u001b[0m Trial 23 finished with value: 0.842391304347826 and parameters: {'n_unit': 13}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:24:28,337]\u001b[0m Trial 24 finished with value: 0.8586956521739131 and parameters: {'n_unit': 10}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:24:46,408]\u001b[0m Trial 25 finished with value: 0.7880434782608695 and parameters: {'n_unit': 8}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:25:03,900]\u001b[0m Trial 26 finished with value: 0.875 and parameters: {'n_unit': 13}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:25:28,608]\u001b[0m Trial 27 finished with value: 0.8315217391304348 and parameters: {'n_unit': 13}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:26:02,135]\u001b[0m Trial 28 finished with value: 0.8695652173913043 and parameters: {'n_unit': 16}. Best is trial 8 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-03 15:26:32,541]\u001b[0m Trial 29 finished with value: 0.7771739130434783 and parameters: {'n_unit': 15}. Best is trial 8 with value: 0.875.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplae_met",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5eb60d146f8faf7ea6865a598c7f2e034e4748de202b0cf2037de6d3aa28423"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
