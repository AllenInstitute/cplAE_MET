---
# Config file for training MET autoencoder (triple modality)
# Modality abbreviations: T -> transcriptomic, E -> electro-physiological, M -> morphological

# Set device:
device: "cpu"

# Set paths:
data_file: data/raw/MET_full_data.npz # Location of Numpy zipped archive (.npz) file containing processed input data

# Set experiment/optimization properties:
experiment: autoencoder # Type of experiment
modalities: [T, E, M] # Which modalities to use in the experiment
num_epochs: 100 # Number of epochs to train
latent_dim: 3 # Dimension of latent space
batch_size: 1000 # Batch size used during training
learning_rate: 0.001 # Learning rate for the ADAM optimizer
check_step: 10 # How often to save model checkpoints
encoder_cross_grad: False # Whether cross-reconstruction gradient should propagate back to encoder
inference: True

variational:
  mapper:
    init: [32]
    mean: [32]
    transf: [32]
  T=E: 1.0
  T=M: 1.0
  E=T: 1.0
  E=M: 1.0
  M=T: 1.0
  M=E: 1.0

# Set validation parameters:
folds: 10 # Number of folds to use for cross-validation
fold_list: [1, 2] # Which folds to run in this experiment (empty list is short for all folds)
val_split: 0.25 # Fraction of data to use for validation (ignored if folds > 0)
seed: 42 # Random seed to use for validation splits

# Set parameters for early stopping:
patience: .inf # How long to wait for improvement of loss
improvement_frac: 0.01 # How much improvement needs to occur for stoppage to be delayed

# Set parameters for gradient freezing:
freeze_modules: [] # Which modules to freeze (format "modality_enc" or "modality_dec")
freeze_patience: 100 # How long to wait for loss improvement
freeze_losses: [] # Which losses to sum together and monitor (specify based on config key)

# Specify which data format(s) to use for each modality
# The corresponding model must accept multiple data batches, one for each format given
# Supported: T -> [logcpm], E -> [pca-ipfx], M  -> [arbors, ivscc]
formats:
  T: [logcpm]
  E: [pca-ipfx]
  M: [ivscc]

# Specify data transformations and corresponding parameters for each modality
# Functions defined in data.py
transform: 
  # logcpm:
  #   binarize: 0.01

# Set criteria for cell specimen inclusion in experiment
# Note that these are applied after the stratified test-validation split
select:
  platforms: [patchseq]

# simulate:
#   counts:
#     logcpm: 10000
#     pca-ipfx: 10000
#     # arbors: 1000
#     ivscc: 10000
#     logcpm_pca-ipfx_ivscc: 1000
#   num_clusters: 5
#   category_std: 1
#   cluster_std: 0.25
#   model_paths: 
#     logcpm: data/simulator/t_arm
#     pca-ipfx: data/simulator/e_arm
#     arbors: data/simulator/m_arm_arbors
#     ivscc: data/simulator/m_arm_ivscc 

# Set modality-type sample fraction for each batch ("native" uses frequency found in data)
# Note that these fractions are computed after the filtering criteria in the "select" field above
modal_frac:
# -- Unimodal --
  T: native
  E: native
  M: native
# -- Bimodal --
  TE: native
  TM: native
  EM: native
# -- Trimodal --
  MET: native

# Specify metric to use for reconstruction losses
losses:
  logcpm: feature_r2
  pca-ipfx: feature_r2
  arbors: sample_r2
  ivscc: sample_r2

# Set auto-encoder architecture
architecture:
  logcpm:
    data_size: [1252]
    out_activation: relu
    init: [256]
    mean: [128]
    cov: [128]
    dropout: 0.5
  pca-ipfx:
    data_size: [82]
    out_activation: linear
    init: [128]
    mean: [64]
    cov: [64]
    dropout: 0.1
    std_frac: 0.05
  arbors:
    data_size: [120, 4, 4]
    out_activation: relu
    int_activation: relu
    conv_params: [[6, 2, 10], [6, 2, 10]] # [(kernel length, stride, channels), ...]
    init: [10]
    mean: [10]
    cov: [10]
    dropout: 0.0
  ivscc:
    data_size: [75]
    out_activation: linear
    init: [64]
    mean: [64]
    cov: [64]
    dropout: 0.1
    std_frac: 0.05
  ivscc_arbors:
    arbors_size: [120, 4, 4]
    ivscc_size: [75]
    conv_params: [[6, 2, 10], [6, 2, 10]] # [(kernel length, stride, channels), ...]
    ivscc: [64]
    shared: [256]
    mean: [128]
    cov: [128]
    arbors_activation: relu
    ivscc_activation: linear
    arbors_dropout: 0.0
    ivscc_dropout: 0.0

# Set loss weights (used when computing the combined loss scalar)
weights:
  # Single letters indicates within-modality reconstruction loss:
  T: 1.0   
  E: 1.0   
  M: 1.0  
  # A-B is the coupling loss between latent spaces of modality A and B, with the gradient only propogated to B
  E-T: 1.0  
  E-M: 1.0
  M-T: 1.0  
  M-E: 1.0
  T-E: 1.0  
  T-M: 1.0 
  # A=B is cross reconstruction loss for modal A generating modality B
  E=T: 1.0  
  E=M: 1.0
  M=T: 1.0  
  M=E: 1.0
  T=E: 1.0 
  T=M: 1.0  

# Set SLURM parameters:
partition: 'celltypes'
cpus: 8
gpus: 1
nodes: 1
memory: '20g'
time: '100:00:00'
directory: '/allen/programs/celltypes/workgroups/mousecelltypes/MachineLearning/Ian/code/cplAE_MET'
conda: 'cplae'