---
# Config file for training MET coupler model

# Set device:
device: "cpu"

# Set paths:
data_file: data/raw/MET_full_data.npz # Location of Numpy zipped archive (.npz) file containing processed input data

# Set experiment/optimization properties:
experiment: coupler # Type of experiment
modalities: [T, E, M] # Which modalities to use in the experiment
num_epochs: 5000 # Number of epochs to train
batch_size: 1000 # Batch size used during training
learning_rate: 0.001 # Learning rate for the ADAM optimizer
check_step: 100 # How often to save model checkpoints
hidden_dims: [64, 64]

# Set validation parameters:
folds: 10 # Number of folds to use for cross-validation
fold_list: [] # Which folds to run in this experiment (empty list is short for all folds)
val_split: 0.25 # Fraction of data to use for validation (ignored if folds > 0)
seed: 42 # Random seed to use for validation splits

# Set parameters for early stopping:
patience: 100 # How long to wait for improvement of loss
improvement_frac: 0.0 # How much improvement needs to occur for stoppage to be delayed

# Specify which data format(s) to use for each modality
# The corresponding model must accept multiple data batches, one for each format given
# Supported: T -> [logcpm], E -> [pca-ipfx], M  -> [arbors, ivscc]
formats:
  T: [logcpm]
  E: [pca-ipfx]
  M: [arbors]

# Specify data transformations and corresponding parameters for each modality
# Functions defined in data.py
transform: 
  # logcpm:
  #   binarize: 0.01

# Set criteria for cell specimen inclusion in experiment
# Note that these are applied after the stratified test-validation split
select:
  platforms: [patchseq]

# simulate:
#   counts:
#     logcpm: 10000
#     pca-ipfx: 10000
#     # arbors: 1000
#     ivscc: 10000
#     logcpm_pca-ipfx_ivscc: 1000
#   num_clusters: 5
#   category_std: 1
#   cluster_std: 0.25
#   model_paths: 
#     logcpm: data/simulator/t_arm
#     pca-ipfx: data/simulator/e_arm
#     arbors: data/simulator/m_arm_arbors
#     ivscc: data/simulator/m_arm_ivscc 

# Set modality-type sample fraction for each batch ("native" uses frequency found in data)
# Note that these fractions are computed after the filtering criteria in the "select" field above
modal_frac:
# -- Bimodal --
  TE: native
  TM: native
  EM: native
# -- Trimodal --
  MET: native

modal_specs:
  T:
    latent_dim: 3
    model_path: "/Users/ian.convy/code/archive/2-24-retraced/patchseq-mse/t_arm"
  E:
    latent_dim: 3
    model_path: "/Users/ian.convy/code/archive/2-24-retraced/patchseq-mse/e_arm"
  M:
    latent_dim: 3
    model_path: "/Users/ian.convy/code/archive/2-24-retraced/patchseq-mse/m_arm"

# Set SLURM parameters:
partition: 'celltypes'
cpus: 8
gpus: 1
nodes: 1
memory: '20g'
time: '100:00:00'
directory: '/allen/programs/celltypes/workgroups/mousecelltypes/MachineLearning/Ian/code/cplAE_MET'
conda: 'cplae'